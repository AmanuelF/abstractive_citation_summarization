{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21599,
     "status": "ok",
     "timestamp": 1636992864579,
     "user": {
      "displayName": "Amanuel Alambo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1kA5oHs9X8VTfaoRu8wK35Yj33QD7CJkOZ6QBgQ=s64",
      "userId": "11985467428571358535"
     },
     "user_tz": 300
    },
    "id": "LS0BC5oErcAP",
    "outputId": "6afd2640-868e-46f3-989e-2da5ac7db63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1704,
     "status": "ok",
     "timestamp": 1636992869030,
     "user": {
      "displayName": "Amanuel Alambo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1kA5oHs9X8VTfaoRu8wK35Yj33QD7CJkOZ6QBgQ=s64",
      "userId": "11985467428571358535"
     },
     "user_tz": 300
    },
    "id": "sT8qQNCSreSW",
    "outputId": "133d3743-be02-45af-9284-35a1e7761de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/apex-codes/citation_sum\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My\\ Drive/Colab\\ Notebooks/apex-codes/citation_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOdoqhT7IJB-"
   },
   "source": [
    "## The ROUGE evaluation is done between a generated summary for a cited article and its abstract (both can be accessed using their cited ids from the respective folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3177,
     "status": "ok",
     "timestamp": 1636992876352,
     "user": {
      "displayName": "Amanuel Alambo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1kA5oHs9X8VTfaoRu8wK35Yj33QD7CJkOZ6QBgQ=s64",
      "userId": "11985467428571358535"
     },
     "user_tz": 300
    },
    "id": "XiH2PcFKNyOd",
    "outputId": "e4f6aca9-3b92-47cf-c13e-7d5bd4669a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3VOaVprJMUu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from rouge import Rouge\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHy5PRF7IC_H"
   },
   "source": [
    "## Evaluation against the groun truth summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3RQXW6EJ25D"
   },
   "outputs": [],
   "source": [
    "def _compute_ROUGE(generated_summary, human_summary):  \n",
    "  rouge = Rouge()\n",
    "  \n",
    "  scores = rouge.get_scores(generated_summary, human_summary)[0]\n",
    "  \n",
    "  rouge_1_f = scores['rouge-1']['f']\n",
    "  rouge_2_f = scores['rouge-2']['f']\n",
    "  rouge_l_f = scores['rouge-l']['f']\n",
    "\n",
    "  rouge_1_f = rouge_1_f * 100\n",
    "  rouge_2_f = rouge_2_f * 100\n",
    "  rouge_l_f = rouge_l_f * 100\n",
    "\n",
    "  return rouge_1_f, rouge_2_f, rouge_l_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb2Rr87XwELf"
   },
   "source": [
    "## Iterate through the directories housing the generated and human summaries and store into a container and do evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq71hbOVqSul"
   },
   "source": [
    "### Call to the ROUGE evaluation method in main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t5KGTNEpRuQ"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  model_name = \"TransFuse\"  # changes with the model used\n",
    "  w_abstract = True\n",
    "\n",
    "  if not w_abstract:\n",
    "    summary_type = \"SUMMARIES_FROM_CITATIONS_ONLY\"   # changes with the summary type\n",
    "  else:\n",
    "    summary_type = \"SUMMARIES_FROM_CITATIONS_AND_RP_ABSTRACT\"\n",
    "\n",
    "  GENERATED_SUMMARY_PATH = f\"{model_name}_Results_SciSummNet/{summary_type}\"\n",
    "  HUMAN_SUMMARY_PATH = \"ScisummNet/scisummnet_release1.1__20190413/top1000_complete\"\n",
    "\n",
    "\n",
    "  # First read all the generated summaries into a dict where the key is the paper_id---same for human summaries---the keys will be used to match the two\n",
    "  dict_generated_summaries = {}\n",
    "  dict_human_summaries = {}\n",
    "\n",
    "  # Read all the generated summaries\n",
    "  for paper_id in os.listdir(GENERATED_SUMMARY_PATH):\n",
    "    paper_id_wo_txt = str(paper_id.replace('.txt', ''))\n",
    "    with open(os.path.join(GENERATED_SUMMARY_PATH, paper_id), 'r') as fp:\n",
    "      summary = fp.read()\n",
    "    fp.close()\n",
    "    dict_generated_summaries[paper_id_wo_txt] = summary\n",
    "\n",
    "  # Read the human summaries\n",
    "  for paper_id in os.listdir(HUMAN_SUMMARY_PATH):\n",
    "    human_summary_path = f\"{HUMAN_SUMMARY_PATH}/{paper_id}/summary\"\n",
    "    with open(f\"{human_summary_path}/{paper_id}.gold.txt\", 'r') as fp:\n",
    "      ground_truth_summary = fp.read()\n",
    "    fp.close()\n",
    "    dict_human_summaries[paper_id] = ground_truth_summary\n",
    "\n",
    "  total_no_summaries = len(dict_generated_summaries)\n",
    "  rouge_1_f_sum, rouge_2_f_sum, rouge_l_f_sum = 0.0, 0.0, 0.0\n",
    "  for paper_id, gen_summary in dict_generated_summaries.items():\n",
    "    human_summary = dict_human_summaries[paper_id]\n",
    "\n",
    "    # call to the ROUGE evaluation method\n",
    "    try:\n",
    "      rouge_1_f, rouge_2_f, rouge_l_f = _compute_ROUGE(gen_summary, human_summary)\n",
    "    except:\n",
    "      continue\n",
    "\n",
    "    rouge_1_f_sum += rouge_1_f\n",
    "    rouge_2_f_sum += rouge_2_f\n",
    "    rouge_l_f_sum += rouge_l_f\n",
    "\n",
    "  avg_rouge_1_f = rouge_1_f_sum/float(total_no_summaries)\n",
    "  avg_rouge_2_f = rouge_2_f_sum/float(total_no_summaries)\n",
    "  avg_rouge_l_f = rouge_l_f_sum/float(total_no_summaries)\n",
    "\n",
    "  print(f\"Final ROUGE-1 wrt human summaries: %.2f\" % avg_rouge_1_f)\n",
    "  print(f\"Final ROUGE-2 wrt human summaries: %.2f\" % avg_rouge_2_f)\n",
    "  print(f\"Final ROUGE-L wrt human summaries: %.2f\" % avg_rouge_l_f)\n",
    "  print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuyl5hfy3MvG"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18skUdfZ44My"
   },
   "source": [
    "## Evaluation against the citation contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71OMwIC-t-aX"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  model_name = \"TransFuse\"  # changes with the model used\n",
    "  w_abstract = True\n",
    "  if not w_abstract:\n",
    "    summary_type = \"SUMMARIES_FROM_CITATIONS_ONLY\"   # changes with the summary type\n",
    "  else:\n",
    "    summary_type = \"SUMMARIES_FROM_CITATIONS_AND_RP_ABSTRACT\"\n",
    "\n",
    "  # Read the citation contexts for each reference paper\n",
    "  DATA_PATH = \"ScisummNet/scisummnet_release1.1__20190413/top1000_complete\"\n",
    "  RESULTS_DIR = f\"{model_name}_Results_SciSummNet\"   # changes based on the model currently being used\n",
    "  dict_citation_contexts = {}\n",
    "\n",
    "\n",
    "  for count, paper_id in enumerate(os.listdir(DATA_PATH)):\n",
    "    citing_sentences = list()   # to store all incoming citing sentences\n",
    "    for file in os.listdir(os.path.join(DATA_PATH, paper_id)):\n",
    "      if file.endswith('.json'):\n",
    "        with open(os.path.join(f\"{DATA_PATH}/{paper_id}\", file), 'r') as fp:\n",
    "          data = json.load(fp)\n",
    "        fp.close()\n",
    "        citing_sentences = [obj['clean_text'] for obj in data]\n",
    "\n",
    "    complete_citing_sentences_str = \" \".join(citing_sentences)\n",
    "    dict_citation_contexts[paper_id] = complete_citing_sentences_str\n",
    "\n",
    "\n",
    "  ###############################################################################\n",
    "\n",
    "  GENERATED_SUMMARY_PATH = f\"{model_name}_Results_SciSummNet/{summary_type}\"\n",
    "  # First read all the generated summaries into a dict where the key is the paper_id---same for human summaries\n",
    "  # ---the keys will be used to match the two\n",
    "  dict_generated_summaries = {}\n",
    "\n",
    "  # Read all the generated summaries\n",
    "  for paper_id in os.listdir(GENERATED_SUMMARY_PATH):\n",
    "    paper_id_wo_txt = str(paper_id.replace('.txt', ''))\n",
    "    with open(os.path.join(GENERATED_SUMMARY_PATH, paper_id), 'r') as fp:\n",
    "      summary = fp.read()\n",
    "    fp.close()\n",
    "    dict_generated_summaries[paper_id_wo_txt] = summary\n",
    "\n",
    "  #########################################################################\n",
    "\n",
    "  total_no_summaries = len(dict_generated_summaries)\n",
    "\n",
    "  rouge_1_f_sum, rouge_2_f_sum, rouge_l_f_sum = 0.0, 0.0, 0.0\n",
    "  for paper_id, gen_summary in dict_generated_summaries.items():\n",
    "    citation_contexts = dict_citation_contexts[paper_id]   # since this is for evaluation against the citation contexts\n",
    "\n",
    "    # call to the ROUGE evaluation method\n",
    "    try:\n",
    "      rouge_1_f, rouge_2_f, rouge_l_f = _compute_ROUGE(gen_summary, citation_contexts)\n",
    "    except:\n",
    "      continue\n",
    "\n",
    "    rouge_1_f_sum += rouge_1_f\n",
    "    rouge_2_f_sum += rouge_2_f\n",
    "    rouge_l_f_sum += rouge_l_f\n",
    "\n",
    "  avg_rouge_1_f = rouge_1_f_sum/float(total_no_summaries)\n",
    "  avg_rouge_2_f = rouge_2_f_sum/float(total_no_summaries)\n",
    "  avg_rouge_l_f = rouge_l_f_sum/float(total_no_summaries)\n",
    "\n",
    "  print(f\"Final ROUGE-1 wrt citation contexts: %.2f\" % avg_rouge_1_f)\n",
    "  print(f\"Final ROUGE-2 wrt citation contexts: %.2f\" % avg_rouge_2_f)\n",
    "  print(f\"Final ROUGE-L wrt citation contexts: %.2f\" % avg_rouge_l_f)\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348042,
     "status": "ok",
     "timestamp": 1636994079862,
     "user": {
      "displayName": "Amanuel Alambo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1kA5oHs9X8VTfaoRu8wK35Yj33QD7CJkOZ6QBgQ=s64",
      "userId": "11985467428571358535"
     },
     "user_tz": 300
    },
    "id": "8qq3yzy_50xW",
    "outputId": "e58a4595-98bd-43c1-b85f-b3c9a075d9d3"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSWBAoNn47he"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ROUGE_Evaluation_SciSummNet_NEW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
